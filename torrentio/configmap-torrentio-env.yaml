apiVersion: v1
kind: ConfigMap
metadata:
  name: torrentio-env
  namespace: torrentio
data:
  # PostgreSQL
  POSTGRES_HOST: "10.43.74.255"
  POSTGRES_PORT: "5432"
  POSTGRES_USER: torrentio
  POSTGRES_USERNAME: torrentio
  # POSTGRES_PASSWORD  - set in secret
  POSTGRES_DATABASE: torrentio
  POSTGRES_DB: torrentio

  # MongoDB
  MONGODB_HOST: "10.43.0.3"
  MONGODB_PORT: "27017"
  MONGODB_DB: torrentio
  MONGO_INITDB_ROOT_USERNAME: mongo
  MONGO_INITDB_ROOT_PASSWORD: mongo

  # Addon
  DEBUG_MODE: "false"

  # Addon and consumer
  MONGODB_USER: mongo
  MONGODB_PASSWORD: mongo

  # Consumer
  RABBIT_URI: amqp://torrentio:torrentio@10.43.0.2:5672/?heartbeat=30
  QUEUE_NAME: ingested
  JOB_CONCURRENCY: "20"
  JOBS_ENABLED: 'true'
  MAX_SINGLE_TORRENT_CONNECTIONS: "10"
  TORRENT_TIMEOUT: "30000"
  UDP_TRACKERS_ENABLED: "true"
  AUTO_CREATE_AND_APPLY_MIGRATIONS: 'false' # Fix for #66 - toggle on for development

  # Producer # Remove these after breaking changes are done
  RabbitMqConfiguration__Host: 10.43.0.2
  RabbitMqConfiguration__QueueName: ingested
  RabbitMqConfiguration__Username: torrentio
  RabbitMqConfiguration__Password: torrentio
  RabbitMqConfiguration__Durable: 'true'
  RabbitMqConfiguration__MaxQueueSize: "0"
  RabbitMqConfiguration__MaxPublishBatchSize: "500"
  RabbitMqConfiguration__PublishIntervalInSeconds: "10"
  # GithubSettings__PAT - set in secret

  # Metadata
  # If true, the metadata will be downloaded once and then the schedule will be ignored
  METADATA_DOWNLOAD_IMDB_DATA_ONCE: "true" # We will run this as a cronjob rather than letting it cron itself
  ## Controls the amount of records processed in memory at any given time during import, higher values will consume more memory
  METADATA_INSERT_BATCH_SIZE: '25000'  

  # RabbitMQ
  RABBITMQ_HOST: 10.43.0.2
  RABBITMQ_USER: torrentio
  RABBITMQ_PASSWORD: torrentio
  RABBITMQ_QUEUE_NAME: ingested
  RABBITMQ_DURABLE: true
  RABBITMQ_MAX_QUEUE_SIZE: "0"
  RABBITMQ_MAX_PUBLISH_BATCH_SIZE: "500"
  RABBITMQ_PUBLISH_INTERVAL_IN_SECONDS: "10"


