apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: csi-nfs
  namespace: csi-nfs
spec:
  chart:
    spec:
      chart: csi-driver-nfs
      version: v4.7.0
      sourceRef:
        kind: HelmRepository
        name: csi-driver-nfs
        namespace: flux-system
  interval: 15m
  timeout: 5m
  releaseName: csi-nfs
  values:
    customLabels: {}
    image:
        baseRepo: registry.k8s.io
        nfs:
            repository: gcr.io/k8s-staging-sig-storage/nfsplugin
            tag: canary
            pullPolicy: IfNotPresent
        csiProvisioner:
            repository: registry.k8s.io/sig-storage/csi-provisioner
            tag: v4.0.0
            pullPolicy: IfNotPresent
        csiSnapshotter:
            repository: registry.k8s.io/sig-storage/csi-snapshotter
            tag: v6.3.3
            pullPolicy: IfNotPresent
        livenessProbe:
            repository: registry.k8s.io/sig-storage/livenessprobe
            tag: v2.12.0
            pullPolicy: IfNotPresent
        nodeDriverRegistrar:
            repository: registry.k8s.io/sig-storage/csi-node-driver-registrar
            tag: v2.10.0
            pullPolicy: IfNotPresent
        externalSnapshotter:
            repository: registry.k8s.io/sig-storage/snapshot-controller
            tag: v6.3.3
            pullPolicy: IfNotPresent

    serviceAccount:
      create: true # When true, service accounts will be created for you. Set to false if you want to use your own.
      controller: csi-nfs-controller-sa # Name of Service Account to be created or used
      node: csi-nfs-node-sa # Name of Service Account to be created or used

    rbac:
      create: true
      name: nfs

    driver:
      name: nfs.csi.k8s.io
      mountPermissions: 0

    feature:
      enableFSGroupPolicy: true
      enableInlineVolume: false
      propagateHostMountOptions: false

    kubeletDir: /var/lib/kubelet

    controller:
      name: csi-nfs-controller
      replicas: 2
      strategyType: Recreate
      runOnMaster: false
      runOnControlPlane: true
      livenessProbe:
        healthPort: 29652
      logLevel: 5
      workingMountDir: /tmp
      dnsPolicy: ClusterFirstWithHostNet  # available values: Default, ClusterFirstWithHostNet, ClusterFirst
      defaultOnDeletePolicy: delete  # available values: delete, retain
      affinity: {}
      nodeSelector: {}
      priorityClassName: system-cluster-critical
      tolerations:
        - key: "node-role.kubernetes.io/master"
          operator: "Exists"
          effect: "NoSchedule"
        - key: "node-role.kubernetes.io/controlplane"
          operator: "Exists"
          effect: "NoSchedule"
        - key: "node-role.kubernetes.io/control-plane"
          operator: "Exists"
          effect: "NoSchedule"
      resources:
        csiProvisioner:
          limits:
            memory: 400Mi
          requests:
            cpu: 10m
            memory: 20Mi
        csiSnapshotter:
          limits:
            memory: 200Mi
          requests:
            cpu: 10m
            memory: 20Mi
        livenessProbe:
          limits:
            memory: 100Mi
          requests:
            cpu: 10m
            memory: 20Mi
        nfs:
          limits:
            memory: 200Mi
          requests:
            cpu: 10m
            memory: 20Mi

    node:
      name: csi-nfs-node
      dnsPolicy: ClusterFirstWithHostNet  # available values: Default, ClusterFirstWithHostNet, ClusterFirst
      maxUnavailable: 1
      logLevel: 5
      livenessProbe:
        healthPort: 29653
      affinity: {}
      nodeSelector: {}
      priorityClassName: system-cluster-critical
      tolerations:
        - operator: "Exists"
      resources:
        livenessProbe:
          limits:
            memory: 100Mi
          requests:
            cpu: 10m
            memory: 20Mi
        nodeDriverRegistrar:
          limits:
            memory: 100Mi
          requests:
            cpu: 10m
            memory: 20Mi
        nfs:
          limits:
            memory: 300Mi
          requests:
            cpu: 10m
            memory: 20Mi

    externalSnapshotter:
      enabled: false
      name: snapshot-controller
      priorityClassName: system-cluster-critical
      controller:
        replicas: 1
      resources:
        limits:
          memory: 300Mi
        requests:
          cpu: 10m
          memory: 20Mi
      # Create volume snapshot CRDs.
      customResourceDefinitions:
        enabled: false   #if set true, VolumeSnapshot, VolumeSnapshotContent and VolumeSnapshotClass CRDs will be created. Set it false, If they already exist in cluster.

    ## Reference to one or more secrets to be used when pulling images
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    imagePullSecrets: []
    # - name: "image-pull-secret"

    ## StorageClass resource example:
    storageClass:
      create: true
      name: nfs-csi
      annotations:
        storageclass.kubernetes.io/is-default-class: "false"
      parameters:
        server: nfs-server.csi-nfs.svc.cluster.local # never actually used, but mandatory for some reason
        share: /
        subDir:
        mountPermissions: "0"
        # csi.storage.k8s.io/provisioner-secret is only needed for providing mountOptions in DeleteVolume
        csi.storage.k8s.io/provisioner-secret-name: "mount-options"
        csi.storage.k8s.io/provisioner-secret-namespace: "csi-nfs"
      reclaimPolicy: Delete
      volumeBindingMode: Immediate
      mountOptions:
        - nfsvers=4.1