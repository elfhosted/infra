apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: mediafusion-dramatiq-worker
  namespace: mediafusion
spec:
  chart:
    spec:
      chart: app-template
      version: 0.2.1
      sourceRef:
        kind: HelmRepository
        name: elfhosted
        namespace: flux-system
  interval: 15m
  timeout: 5m
  releaseName: mediafusion-dramatiq-worker
  values:
    global:
      nameOverride: mediafusion
    image:
      repository: ghcr.io/geek-cookbook/mediafusion
      tag: 3.7.5@sha256:2090df6403bd6cb2a2cda5a57ed11f940dcaa44818857c03a8db769f35cd1e7c
    command: ["pipenv", "run", "dramatiq-gevent", "api.task"]
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      readOnlyRootFilesystem: true
    podSecurityContext:
      seccompProfile:
        type: RuntimeDefault
      runAsUser: 568
      runAsGroup: 568
    automountServiceAccountToken: false
    controller:
      replicas: 1
      annotations:
        configmap.reloader.stakater.com/reload: "mediafusion-env"
        secret.reloader.stakater.com/reload: "mediafusion-env"
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution: 
        - weight: 100  
          podAffinityTerm:    
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - mediafusion
            topologyKey: "kubernetes.io/hostname"
    persistence:
      tmp: 
        enabled: true
        type: custom
        mountPath: /tmp
        volumeSpec:
          ephemeral:
            volumeClaimTemplate:
              metadata:
                labels:
                  velero.io/exclude-from-backup: "true"               
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "topolvm-provisioner-thin"
                resources:
                  requests:
                    storage: 1Gi   
      local: 
        enabled: true
        type: custom
        mountPath: /.local
        volumeSpec:
          ephemeral:
            volumeClaimTemplate:
              metadata:
                labels:
                  velero.io/exclude-from-backup: "true"               
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "topolvm-provisioner-thin"
                resources:
                  requests:
                    storage: 1Gi    
      scrapy: 
        enabled: true
        type: custom
        mountPath: /mediafusion/.scrapy
        volumeSpec:
          ephemeral:
            volumeClaimTemplate:
              metadata:
                labels:
                  velero.io/exclude-from-backup: "true"               
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "topolvm-provisioner-thin"
                resources:
                  requests:
                    storage: 10Gi                                                        
    envFrom:
    - secretRef:
        name: mediafusion-env 
    - configMapRef:
        name: mediafusion-env 

    # resources:
    ingress:
      main:
        enabled: false
    service:
      main:
        enabled: false # don't want probes
        ports:
          http:
            port: 1234 # doesn't matter

    addons:
      vpn:
        enabled: true # in case we ever need it
        gluetun:
          image:
            repository: thrnz/docker-wireguard-pia
            tag: latest
        envFrom:
        - secretRef:
            name: mediafusion-vpn
        env:
          IPTABLES_BACKEND: nft
          KILLSWITCH: "true"
          LOCAL_NETWORK: 10.2.0.0/15,10.43.0.0/16
          LOC: de-frankfurt
          PORT_FORWARDING: "0"
          PORT_PERSIST: "1"
          NFTABLES: "1"       
          VPNDNS: "0" 
        securityContext:
          runAsUser: 0
          capabilities:
            add:
              - NET_ADMIN
              - SYS_MODULE
        config: # We have to set this to null so that we can override with our own config                   