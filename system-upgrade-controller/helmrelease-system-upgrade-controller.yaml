apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: system-upgrade-controller
  namespace: system-upgrade-controller
spec:
  chart:
    spec:
      chart: system-upgrade-controller
      version: 0.3.x
      sourceRef:
        kind: HelmRepository
        name: nimbolus
        namespace: flux-system
  interval: 15m
  timeout: 5m
  releaseName: system-upgrade-controller
  values:
    # Default values for system-upgrade-controller.
    # This is a YAML-formatted file.
    # Declare variables to be passed into your templates.

    replicaCount: 1

    image:
      repository: rancher/system-upgrade-controller
      pullPolicy: IfNotPresent
      # Overrides the image tag whose default is the chart appVersion.
      tag: ""

    imagePullSecrets: []
    nameOverride: ""
    fullnameOverride: ""

    serviceAccount:
      # Annotations to add to the service account
      annotations: {}
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""

    podAnnotations: {}

    podSecurityContext: {}
      # fsGroup: 2000

    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
      runAsGroup: 65534
      allowPrivilegeEscalation: false
      seccompProfile:
        type: RuntimeDefault
      capabilities:
        drop:
          - ALL

    resources: {}
      # We usually recommend not to specify default resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

    nodeSelector: {}

    tolerations:
      - key: "CriticalAddonsOnly"
        operator: "Exists"
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/controlplane"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/etcd"
        operator: "Exists"
        effect: "NoExecute"

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - {key: "node-role.kubernetes.io/control-plane", operator: Exists}

    configEnv:
      SYSTEM_UPGRADE_CONTROLLER_DEBUG: "false"
      SYSTEM_UPGRADE_CONTROLLER_THREADS: "2"
      SYSTEM_UPGRADE_JOB_ACTIVE_DEADLINE_SECONDS: "900"
      SYSTEM_UPGRADE_JOB_BACKOFF_LIMIT: "99"
      SYSTEM_UPGRADE_JOB_IMAGE_PULL_POLICY: "Always"
      SYSTEM_UPGRADE_JOB_KUBECTL_IMAGE: "rancher/kubectl:v1.29.0"
      SYSTEM_UPGRADE_JOB_PRIVILEGED: "true"
      SYSTEM_UPGRADE_JOB_TTL_SECONDS_AFTER_FINISH: "900"
      SYSTEM_UPGRADE_PLAN_POLLING_INTERVAL: "15m"
